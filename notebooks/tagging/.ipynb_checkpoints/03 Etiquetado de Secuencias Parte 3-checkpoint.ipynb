{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Etiquetado de Secuencias: Parte 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Corpus de Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_sents = [\n",
    "    list(zip('El gato come pescado .'.split(),\n",
    "         'D N V N P'.split())),\n",
    "    list(zip('La gata come salmón .'.split(),\n",
    "         'D N V N P'.split())),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('El', 'D'), ('gato', 'N'), ('come', 'V'), ('pescado', 'N'), ('.', 'P')],\n",
       " [('La', 'D'), ('gata', 'N'), ('come', 'V'), ('salmón', 'N'), ('.', 'P')]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Extracción de Features\n",
    "\n",
    "Primero definimos la función que extrae los features para cada palabra en forma de diccionario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(word):\n",
    "    return {\n",
    "        'lower': word.lower(),\n",
    "        'istitle': word.istitle(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora convertimos el corpus dos listas con las instancias X y sus etiquetas y_true:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y_true = []\n",
    "for sent in tagged_sents:\n",
    "    for word, tag in sent:\n",
    "        x = features(word)\n",
    "        X.append(x)\n",
    "        y_true.append(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'lower': 'el', 'istitle': True}, 'D'),\n",
       " ({'lower': 'gato', 'istitle': False}, 'N'),\n",
       " ({'lower': 'come', 'istitle': False}, 'V'),\n",
       " ({'lower': 'pescado', 'istitle': False}, 'N'),\n",
       " ({'lower': '.', 'istitle': False}, 'P'),\n",
       " ({'lower': 'la', 'istitle': True}, 'D'),\n",
       " ({'lower': 'gata', 'istitle': False}, 'N'),\n",
       " ({'lower': 'come', 'istitle': False}, 'V'),\n",
       " ({'lower': 'salmón', 'istitle': False}, 'N'),\n",
       " ({'lower': '.', 'istitle': False}, 'P')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(X, y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Vectorización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos DictVectorizer de scikit-learn para vectorizar.\n",
    "\n",
    "Primero instanciamos el vectorizador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "vect = DictVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego lo \"entrenamos\". El entrenamiento sólo define un mapeo entre los features y las columnas de los vectores de salida:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DictVectorizer(dtype=<class 'numpy.float64'>, separator='=', sort=True,\n",
       "               sparse=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['istitle',\n",
       " 'lower=.',\n",
       " 'lower=come',\n",
       " 'lower=el',\n",
       " 'lower=gata',\n",
       " 'lower=gato',\n",
       " 'lower=la',\n",
       " 'lower=pescado',\n",
       " 'lower=salmón']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego podemos usarlo para vectorizar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x9 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = vect.transform(X[0])\n",
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los vectores resultantes son \"sparse\" porque en su mayoría contienen ceros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 1., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.transform({'lower': 'gato', 'istitle': True}).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Clasificación\n",
    "\n",
    "Usaremos el clasificador MultinomialNB. Primero instanciamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego vectorizamos y entrenamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2 = vect.transform(X)\n",
    "clf.fit(X2, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora el clasificador está listo para predecir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['D'], dtype='<U1')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = {'lower': 'el', 'istitle': True}\n",
    "x2 = vect.transform(x)\n",
    "clf.predict(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos así etiquetar una nueva oración:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['D', 'N', 'V', 'N', 'P'], dtype='<U1')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = 'Lx gatx come melón .'.split()\n",
    "\n",
    "X_test = [features(word) for word in sent]\n",
    "X2_test = vect.transform(X_test)\n",
    "y_pred = clf.predict(X2_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta:** ¿Porqué clasificó bien las palabras nuevas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. Pipelines\n",
    "\n",
    "Podemos usar pipelines para secuenciar componentes. Esto permite entrenarlos y usarlos juntos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', DictVectorizer()),\n",
    "    ('clf', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X, y_true);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y lo usamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['D', 'N', 'V', 'N', 'P'], dtype='<U1')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = 'Lx gatx come melón .'.split()\n",
    "\n",
    "X_test = [features(word) for word in sent]\n",
    "y_pred = pipeline.predict(X_test)\n",
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
